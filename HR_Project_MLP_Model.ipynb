{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b10d29d-17a7-48e1-b0e3-bf923e1d579f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m regularizers\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Suppress TensorFlow info messages\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Suppress TensorFlow info messages\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "def enhanced_preprocessing():\n",
    "    df = pd.read_csv('HR_Employee_Cleaned.csv')\n",
    "    \n",
    "    # Handle missing values if any\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Convert categoricals using label encoding where ordinal\n",
    "    ordinal_features = ['Education', 'JobLevel', 'StockOptionLevel']\n",
    "    for col in ordinal_features:\n",
    "        df[col] = df[col].astype('category').cat.codes\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('Attrition', axis=1)\n",
    "    y = df['Attrition']\n",
    "    \n",
    "    # Handle class imbalance with SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_res, y_res = smote.fit_resample(X, y)\n",
    "    \n",
    "    # Robust scaling for numerical features\n",
    "    scaler = RobustScaler()\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns\n",
    "    X_res[numerical_features] = scaler.fit_transform(X_res[numerical_features])\n",
    "    \n",
    "    return X_res.values, y_res.values\n",
    "\n",
    "def build_optimized_model(input_shape, hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(tf.keras.layers.Input(shape=(input_shape,)))\n",
    "    \n",
    "    # Hidden layers with dropout and regularization\n",
    "    for _ in range(hp['num_layers']):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            hp['hidden_units'],\n",
    "            activation='relu',\n",
    "            kernel_regularizer=regularizers.l2(hp['l2_reg'])))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(hp['dropout_rate']))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Custom learning rate schedule\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=hp['learning_rate'],\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.9)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy',\n",
    "                        tf.keras.metrics.Precision(name='precision'),\n",
    "                        tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "def main(argv=None):\n",
    "    X, y = enhanced_preprocessing()\n",
    "    \n",
    "    # Hyperparameter configuration\n",
    "    hp = {\n",
    "        'num_layers': FLAGS.num_layers,\n",
    "        'hidden_units': FLAGS.hidden_units,\n",
    "        'l2_reg': FLAGS.l2_reg,\n",
    "        'dropout_rate': FLAGS.dropout_rate,\n",
    "        'learning_rate': FLAGS.learning_rate,\n",
    "        'batch_size': FLAGS.batch_size,\n",
    "        'epochs': FLAGS.epochs\n",
    "    }\n",
    "    \n",
    "    # Cross-validation setup\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    fold = 1\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        print(f\"\\nFold {fold} - {'-'*30}\")\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model = build_optimized_model(X_train.shape[1], hp)\n",
    "        \n",
    "        # Early stopping callback\n",
    "        es = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True)\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=hp['epochs'],\n",
    "            batch_size=hp['batch_size'],\n",
    "            callbacks=[es],\n",
    "            verbose=1)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
    "        print(f\"\\nFold {fold} Classification Report:\")\n",
    "        print(classification_report(y_val, y_pred))\n",
    "        \n",
    "        fold += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--num_layers', type=int, default=3,\n",
    "                      help='Number of hidden layers')\n",
    "    parser.add_argument('--hidden_units', type=int, default=64,\n",
    "                      help='Number of units per hidden layer')\n",
    "    parser.add_argument('--l2_reg', type=float, default=0.001,\n",
    "                      help='L2 regularization factor')\n",
    "    parser.add_argument('--dropout_rate', type=float, default=0.3,\n",
    "                      help='Dropout rate between layers')\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.001,\n",
    "                      help='Initial learning rate')\n",
    "    parser.add_argument('--batch_size', type=int, default=32,\n",
    "                      help='Training batch size')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                      help='Maximum training epochs')\n",
    "    \n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d05165-1f1c-4bb5-945c-aec7562e26ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "python script.py --num_layers 4 --hidden_units 128 --l2_reg 0.0001 --dropout_rate 0.2 --learning_rate 0.0005 --batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running the MLP model code in HR_Project_MLP_Model.ipynb\n",
    "\n",
    "# 1. Training History Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Attrition', 'Attrition'], \n",
    "            yticklabels=['No Attrition', 'Attrition'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('MLP Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 3. ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_proba = model.predict(X_val)\n",
    "fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('MLP ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
